{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4e8XG6XtsRrBvCJ7RVbt/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ishwarya-2004/Fashion-trend-forecasting/blob/main/Fashion_Trend_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "We9p5FGKp43x"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import datetime\n",
        "import re\n",
        "from collections import Counter\n",
        "from difflib import get_close_matches\n",
        "import praw\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load Dataset\n",
        "file_path = \"Fashion_Retail_Sales_Modified.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "df[\"Date Purchase\"] = pd.to_datetime(df[\"Date Purchase\"], errors=\"coerce\")\n",
        "df[\"Month\"] = df[\"Date Purchase\"].dt.to_period(\"M\").dt.to_timestamp()\n",
        "unique_countries = df[\"Country\"].dropna().unique()\n",
        "\n",
        "# Reddit API\n",
        "reddit = praw.Reddit(\n",
        "    client_id=\"\",\n",
        "    client_secret=\"\",\n",
        "    user_agent=\"fashion-trend-app\"\n",
        ")\n",
        "\n",
        "# Unsplash API\n",
        "UNSPLASH_ACCESS_KEY = \"\"\n",
        "IMAGE_DIR = \"fashion_images\"\n",
        "if not os.path.exists(IMAGE_DIR):\n",
        "    os.makedirs(IMAGE_DIR)\n",
        "\n",
        "# Load Pretrained ResNet Model\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    return transform(image).unsqueeze(0)\n",
        "\n",
        "def extract_features(image_path):\n",
        "    image_tensor = preprocess_image(image_path)\n",
        "    with torch.no_grad():\n",
        "        features = model(image_tensor)\n",
        "    return features.numpy().flatten()\n",
        "\n",
        "def fetch_fashion_images(product, num_images=5):\n",
        "    url = f\"https://api.unsplash.com/search/photos?query={product}&per_page={num_images}&client_id={UNSPLASH_ACCESS_KEY}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        return [\"Error fetching images from Unsplash.\"]\n",
        "    data = response.json()\n",
        "    image_paths = []\n",
        "    for i, item in enumerate(data[\"results\"]):\n",
        "        img_url = item[\"urls\"][\"regular\"]\n",
        "        img_path = os.path.join(IMAGE_DIR, f\"{product.replace(' ', '_')}_{i}.jpg\")\n",
        "        img_data = requests.get(img_url).content\n",
        "        with open(img_path, \"wb\") as handler:\n",
        "            handler.write(img_data)\n",
        "        image_paths.append(img_path)\n",
        "    return image_paths\n",
        "\n",
        "def select_best_image(product):\n",
        "    image_paths = fetch_fashion_images(product, num_images=5)\n",
        "    if not image_paths:\n",
        "        return None\n",
        "    feature_vectors = np.array([extract_features(img) for img in image_paths])\n",
        "    distances = np.linalg.norm(feature_vectors - feature_vectors.mean(axis=0), axis=1)\n",
        "    best_idx = np.argmin(distances)\n",
        "    return image_paths[best_idx]\n",
        "\n",
        "def get_products(selected_country):\n",
        "    if selected_country in unique_countries:\n",
        "        return df[df[\"Country\"] == selected_country][\"Item Purchased\"].dropna().unique().tolist()\n",
        "    return []\n",
        "\n",
        "month_festivals = {\n",
        "    \"January\": [\"London Textile Fair (UK)\", \"Berlin Fashion Week (Germany)\"],\n",
        "    \"February\": [\"New York Fashion Week (USA)\", \"London Fashion Week (UK)\"],\n",
        "    \"March\": [\"Los Angeles Fashion Week (USA)\"],\n",
        "    \"April\": [\"Coachella Festival Fashion Trends (USA)\"],\n",
        "    \"May\": [\"Met Gala (USA)\"],\n",
        "    \"June\": [\"Royal Ascot Fashion Event (UK)\"],\n",
        "    \"July\": [\"Miami Swim Week (USA)\", \"Berlin Fashion Week (Germany)\"],\n",
        "    \"August\": [\"Bread & Butter by Zalando (Germany)\"],\n",
        "    \"September\": [\"New York Fashion Week (USA)\", \"London Fashion Week (UK)\"],\n",
        "    \"October\": [\"Los Angeles Fashion Week (USA)\"],\n",
        "    \"November\": [\"Black Friday Sales (USA, UK, Germany)\"],\n",
        "    \"December\": [\"Christmas Fashion Markets (Global)\", \"New Year Shopping Events (Global)\"]\n",
        "}\n",
        "\n",
        "def get_upcoming_festivals(date):\n",
        "    try:\n",
        "        date = pd.to_datetime(date, errors='coerce')\n",
        "        if pd.isna(date):\n",
        "            return \"Invalid date format.\"\n",
        "        months = [(date.month + i - 1) % 12 + 1 for i in range(3)]\n",
        "        festival_list = []\n",
        "        for m in months:\n",
        "            month_name = pd.to_datetime(f\"2025-{m}-01\").strftime(\"%B\")\n",
        "            festival_list.extend(month_festivals.get(month_name, []))\n",
        "        return \", \".join(festival_list) if festival_list else \"No festivals found.\"\n",
        "    except:\n",
        "        return \"Error fetching festivals.\"\n",
        "\n",
        "# Get trending fashion keywords from Reddit\n",
        "from fashion_trends import fashion_trends\n",
        "\n",
        "# Function to get trending fashion keywords for a given month\n",
        "def get_trending_fashion_keywords(month):\n",
        "    return fashion_trends.get(month.lower().strip(), [])\n",
        "\n",
        "# Example usage\n",
        "def display_fashion_trends(month):\n",
        "    trends = get_trending_fashion_keywords(month)\n",
        "    if trends:\n",
        "        print(f\"Trending fashion for {month.capitalize()}:\")\n",
        "        for trend in trends:\n",
        "            print(f\"- {trend}\")\n",
        "    else:\n",
        "        print(f\"No fashion trends available for {month.capitalize()}.\")\n",
        "\n",
        "# Input the month you want to check trends for\n",
        "month_input = input(\"Enter a month: \")\n",
        "display_fashion_trends(month_input)\n",
        "# Sentiment analysis from Reddit comments\n",
        "def get_sentiment_pie(product):\n",
        "    subreddit = reddit.subreddit(\"fashion\")\n",
        "    sentiments = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "    for post in subreddit.search(product, sort=\"relevance\", limit=10):\n",
        "        post.comments.replace_more(limit=0)\n",
        "        for comment in post.comments[:20]:\n",
        "            blob = TextBlob(comment.body)\n",
        "            polarity = blob.sentiment.polarity\n",
        "            if polarity > 0.1:\n",
        "                sentiments[\"positive\"] += 1\n",
        "            elif polarity < -0.1:\n",
        "                sentiments[\"negative\"] += 1\n",
        "            else:\n",
        "                sentiments[\"neutral\"] += 1\n",
        "    total = sum(sentiments.values())\n",
        "    if total == 0:\n",
        "        sentiments = {\"positive\": 33, \"neutral\": 34, \"negative\": 33}\n",
        "    else:\n",
        "        for key in sentiments:\n",
        "            sentiments[key] = (sentiments[key] / total) * 100\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.pie(sentiments.values(), labels=sentiments.keys(), autopct='%1.1f%%',\n",
        "           startangle=90, colors=[\"#4CAF50\", \"#FFC107\", \"#F44336\"])\n",
        "    ax.set_title(\"Fashion Sentiment Analysis\")\n",
        "    plt.savefig(\"sentiment_pie_chart.png\")\n",
        "    plt.close()\n",
        "    return \"sentiment_pie_chart.png\"\n",
        "\n",
        "def forecast_sales(selected_country, selected_product, future_date, future_units):\n",
        "    if selected_country not in unique_countries:\n",
        "        return \"Invalid Country\", None, None, [], None\n",
        "    country_data = df[df[\"Country\"] == selected_country]\n",
        "    if selected_product not in country_data[\"Item Purchased\"].dropna().unique():\n",
        "        return \"Invalid Product\", None, None, [], None\n",
        "\n",
        "    product_data = country_data[country_data[\"Item Purchased\"] == selected_product]\n",
        "    product_data = product_data.groupby(\"Month\")[\"Purchase Amount (USD)\"].sum().reset_index().sort_values(\"Month\")\n",
        "    try:\n",
        "        model = SARIMAX(product_data[\"Purchase Amount (USD)\"], order=(1,1,1), seasonal_order=(1,1,1,12)).fit()\n",
        "        forecast_steps = 36\n",
        "        forecast = model.get_forecast(steps=forecast_steps).predicted_mean\n",
        "        forecast_dates = pd.date_range(start=product_data[\"Month\"].max(), periods=forecast_steps + 1, freq=\"M\")[1:]\n",
        "\n",
        "        future_date_parsed = pd.to_datetime(future_date, errors=\"coerce\")\n",
        "        if future_date_parsed is pd.NaT or not (forecast_dates[0] <= future_date_parsed <= forecast_dates[-1]):\n",
        "            return f\"Error: Date out of range ({forecast_dates[0].strftime('%Y-%m')} to {forecast_dates[-1].strftime('%Y-%m')})\", None, None, [], None\n",
        "\n",
        "        closest_date = min(forecast_dates, key=lambda x: abs(x - future_date_parsed))\n",
        "        revenue = (forecast.iloc[list(forecast_dates).index(closest_date)] / max(product_data[\"Purchase Amount (USD)\"].mean(), 1)) * future_units\n",
        "\n",
        "        pie_path = get_sentiment_pie(selected_product)\n",
        "        festivals = get_upcoming_festivals(future_date)\n",
        "        month_name = pd.to_datetime(future_date).strftime(\"%B\")\n",
        "        trending_products = get_trending_fashion_keywords(month_name)\n",
        "\n",
        "        if selected_product.lower() in trending_products:\n",
        "            trend_msg = \"âœ… Your selected product is in trend!\"\n",
        "            trending_image_paths = []\n",
        "        else:\n",
        "            trend_msg = f\"âŒ Your selected product is not in trend.\\nTrending Products for {month_name}: {', '.join(trending_products)}\"\n",
        "            trending_image_paths = [select_best_image(p) for p in trending_products]\n",
        "\n",
        "        return (\n",
        "            f\"Predicted Revenue: ${revenue:.2f}\\nFestive Seasons: {festivals}\\n{trend_msg}\",\n",
        "            pie_path,\n",
        "            [select_best_image(selected_product)],\n",
        "            trending_image_paths,\n",
        "            f\"Trending Products for {month_name}\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", None, None, [], None\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ðŸ›ï¸ Fashion Trend & Sales Forecasting App\")\n",
        "\n",
        "    selected_country = gr.Dropdown(choices=unique_countries.tolist(), label=\"ðŸŒ Select Country\")\n",
        "    selected_product = gr.Dropdown(choices=[], label=\"ðŸ‘— Select Product\")\n",
        "    selected_country.change(fn=lambda x: gr.update(choices=get_products(x)), inputs=[selected_country], outputs=[selected_product])\n",
        "\n",
        "    future_date = gr.Textbox(label=\"ðŸ“… Enter Future Sale Date (YYYY-MM)\")\n",
        "    future_units = gr.Number(label=\"ðŸ“¦ Expected Units Sold\")\n",
        "    submit_button = gr.Button(\"ðŸ” Predict & Get Trends\")\n",
        "\n",
        "    output_text = gr.Textbox(label=\"ðŸ“ˆ Forecast Summary & Trend Info\")\n",
        "    output_image = gr.Image(label=\"ðŸ“Š Sentiment Analysis Pie Chart\")\n",
        "    output_gallery = gr.Gallery(label=\"ðŸ–¼ï¸ Selected Product Image\")\n",
        "    trending_heading = gr.Textbox(visible=False)\n",
        "    trending_gallery = gr.Gallery(label=\"ðŸŒŸ Trending Product Images\")\n",
        "\n",
        "    feedback = gr.Radio([\"ðŸ‘ Good\", \"ðŸ‘Ž Needs Improvement\"], label=\"ðŸ’¬ Your Feedback\")\n",
        "\n",
        "    submit_button.click(\n",
        "        fn=forecast_sales,\n",
        "        inputs=[selected_country, selected_product, future_date, future_units],\n",
        "        outputs=[output_text, output_image, output_gallery, trending_gallery, trending_heading]\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ]
    }
  ]
}